#!/usr/bin/env python
# -*- coding: UTF-8 -*-
'''
@Author  ：Qing
@Date    ：
@Use     ：
'''
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.model_selection import ShuffleSplit, GridSearchCV, train_test_split, StratifiedShuffleSplit, learning_curve
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, \
    f1_score
from sklearn.tree import export_graphviz
import graphviz
import matplotlib.pyplot as plt
import seaborn as sns


data = pd.read_csv("*.csv")
# 提取特征和标签
X = data.drop("lithology", axis=1)
y = data["lithology"]

# 将数据分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)

# 创建随机森林模型
rf = RandomForestClassifier(n_estimators=100, random_state=42,criterion='gini')

# 训练模型
rf.fit(X_train, y_train)


# 在测试集上进行预测
y_pred = rf.predict(X_test)

# 计算准确率
accuracy = accuracy_score(y_test, y_pred)
print("准确率：", accuracy)


# 网格搜索，参数优化
estimator = RandomForestClassifier(n_estimators=100, random_state=42,criterion='gini')

param_grid = {
    #400,20,2,0.82394
    'n_estimators': [400],
    'max_depth': [20],
    'min_samples_split': [2]
}
model = GridSearchCV(estimator, param_grid)
model.fit(X_train, y_train)
print('Best parameters found by grid search are:', model.best_params_)
# 模型预测
y_pred_best = model.predict(X_test)
# 模型评估
print('The accuracy of prediction is:', accuracy_score(y_test, y_pred_best))

#保存模型
import joblib
#保存模型
joblib.dump(model,'*.pkl')


'''
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc

# 将目标变量进行二值化
y_test_bin = label_binarize(y_test, classes=[1,2,3,4,5])  # 根据实际情况修改类别

# 计算混淆矩阵
confusion = confusion_matrix(y_test, y_pred_best)

plt.figure(figsize=(10, 7))
plt.imshow(confusion, cmap='binary', alpha=0.0)

# 添加文本标签
for i in range(len(confusion)):
    for j in range(len(confusion)):
        plt.text(j, i, format(confusion[i, j], ".2f"),
                    ha="center", va="center", color="black", fontsize=15)
# 绘制边框线
plt.gca().patch.set_edgecolor('black')
plt.gca().patch.set_linewidth(1)
# 设置坐标轴标签
plt.xticks(np.arange(len(confusion)), model.classes_, fontsize=16)
plt.yticks(np.arange(len(confusion)), model.classes_, fontsize=16)
# 添加标题
plt.title('CORRELATION MATRIX\n', fontsize=18)

accuracy = accuracy_score(y_test, y_pred_best)
precision = precision_score(y_test, y_pred_best, average='weighted')
recall = recall_score(y_test, y_pred_best, average='weighted')
f1 = f1_score(y_test, y_pred_best, average='weighted')
print("准确率：", accuracy)
print("精确率：", precision)
print("召回率：", recall)
print("F1-score：", f1)

# 计算每个类别的概率预测值
y_scores = model.predict_proba(X_test)

# 计算每个类别的ROC曲线和AUC值
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(len(model.classes_)):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_scores[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# 绘制每个类别的ROC曲线
plt.figure()
colors = ['blue', 'red', 'green', 'orange','yellow']  # 根据实际情况修改颜色
for i in range(len(model.classes_)):
    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label='ROC curve (area = %0.2f)' % roc_auc[i])

plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')
# plt.xlim([0.0, 1.0])
# plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()


from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression

# 定义k折交叉验证
kfold = KFold(n_splits=5, shuffle=True, random_state=32)  # 根据需要选择折数，设置随机种子和是否需要打乱数据
# 进行交叉验证
scores = cross_val_score(model, X, y, cv=kfold)  # 根据需要选择特征和目标变量
# 打印每折的准确率
print("Cross-validation scores:", scores)
# 打印准确率的平均值和标准差
print("Average accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
'''
test = pd.read_csv("*.csv").drop("lithology", axis=1)
pre = model.predict(test)
