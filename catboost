#!/usr/bin/env python
# -*- coding: UTF-8 -*-
'''
@Author  ：Qing
@Date    ：
@Use     ：
'''
# 导入必要的库
import catboost as cb
import numpy as np
import pandas as pd
from catboost import CatBoostClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import seaborn as sns
import matplotlib.pyplot as plt

data = pd.read_csv("E:\\PycharmProjects\\DeepLearning\\data\\lith_data2.csv")
# 提取特征和标签
X = data.drop("lithology", axis=1)
y = data["lithology"]

# 将数据分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)

# 创建CatBoost分类器
model = cb.CatBoostClassifier(iterations=100, learning_rate=0.1, depth=5)

# 训练模型
model.fit(X_train, y_train, verbose=False)

# 在测试集上进行预测
y_pred = model.predict(X_test)

# 计算准确率
accuracy = accuracy_score(y_test, y_pred)
print("准确率：", accuracy)


# 网格搜索，参数优化
estimator = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=5)

param_grid = {
    #800,0.2,8  0.8352
    'iterations': [800],
    'learning_rate': [0.2],
    'depth': [8]
}
model = GridSearchCV(estimator, param_grid)
model.fit(X_train, y_train)
print('Best parameters found by grid search are:', model.best_params_)
# 模型预测
y_pred_best = model.predict(X_test)
# 模型评估
print('The accuracy of prediction is:', accuracy_score(y_test, y_pred_best))

import joblib

#保存模型
joblib.dump(model,'E:/PycharmProjects/DeepLearning/model_pkl/catboost_model.pkl')

'''
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
# 将目标变量进行二值化
y_test_bin = label_binarize(y_test, classes=[1,2,3,4,5])  # 根据实际情况修改类别


# 计算混淆矩阵
confusion = confusion_matrix(y_test, y_pred_best)

plt.figure(figsize=(10, 7))
plt.imshow(confusion, cmap='binary', alpha=0.0)

# 添加文本标签
for i in range(len(confusion)):
    for j in range(len(confusion)):
        plt.text(j, i, format(confusion[i, j], ".2f"),
                    ha="center", va="center", color="black", fontsize=15)
# 绘制边框线
plt.gca().patch.set_edgecolor('black')
plt.gca().patch.set_linewidth(1)
# 设置坐标轴标签
plt.xticks(np.arange(len(confusion)), model.classes_, fontsize=16)
plt.yticks(np.arange(len(confusion)), model.classes_, fontsize=16)
# 添加标题
plt.title('CORRELATION MATRIX\n', fontsize=18)


accuracy = accuracy_score(y_test, y_pred_best)
precision = precision_score(y_test, y_pred_best, average='weighted')
recall = recall_score(y_test, y_pred_best, average='weighted')
f1 = f1_score(y_test, y_pred_best, average='weighted')
print("准确率：", accuracy)
print("精确率：", precision)
print("召回率：", recall)
print("F1-score：", f1)



# 计算每个类别的概率预测值
y_scores = model.predict_proba(X_test)

# 计算每个类别的ROC曲线和AUC值
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(len(model.classes_)):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_scores[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# 绘制每个类别的ROC曲线
plt.figure()
colors = ['blue', 'red', 'green', 'orange','yellow']  # 根据实际情况修改颜色
for i in range(len(model.classes_)):
    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label='ROC curve (area = %0.2f)' % roc_auc[i])

plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')
# plt.xlim([0.0, 1.0])
# plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()


from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression

# 定义k折交叉验证
kfold = KFold(n_splits=5, shuffle=True, random_state=32)  # 根据需要选择折数，设置随机种子和是否需要打乱数据
# 进行交叉验证
scores = cross_val_score(model, X, y, cv=kfold)  # 根据需要选择特征和目标变量
# 打印每折的准确率
print("Cross-validation scores:", scores)
# 打印准确率的平均值和标准差
print("Average accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))


# 计算均值和标准差
train_mean = -np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = -np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

# 绘制误差带
plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')
plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color='red')

# 设置图像属性
plt.xlabel('Training set size')
plt.ylabel('Error')
plt.title('Learning Curve')
plt.legend(loc='best')
plt.grid(True)
plt.show()
'''
